{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5b5d05-06ad-4463-8b81-47679d1bbc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports and setup \n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import numpy as np\n",
    "\n",
    "import statsmodels.formula.api as sm\n",
    "\n",
    "#%matplotlib notebook\n",
    "import matplotlib.pyplot as plt \n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline  \n",
    "plt.rcParams['figure.figsize'] = (10, 6) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a97930-c77c-4fd5-acec-302414296104",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pe_original = pd.read_csv('DKA - Physical.csv')\n",
    "df_pe_original = pd.read_csv('PHYSEXAM.csv')\n",
    "\n",
    "df_pe_original.head()\n",
    "\n",
    "pd.set_option('display.max_columns', None) # View max columns\n",
    "print(df_pe_original.columns.to_list())\n",
    "\n",
    "df_pe_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c968819-6cd9-4b55-a82e-8b5bcf65ff69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking - are these all study initiation events? - yes\n",
    "df_pe_original['StudyEvent'].value_counts() \n",
    "df_pe_original['PUDID'].nunique() #1389 - ok, one row per patient\n",
    "#len(df_pe_original) #1389"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0fcbd0-1bc0-44b4-a6d3-ec5e8ca18028",
   "metadata": {},
   "source": [
    "This is now a markdown cell\n",
    "\n",
    "# This cell is duplicated via function in the cell below now\n",
    "df_pe = df_pe_original[['PUDID', 'PETime', 'PEHEENT', 'PEHEENTDesc', 'PECardio', 'PECardioDesc', \n",
    "                        'PEResp', 'PERespDesc', 'PEGI', 'PEGIDesc', 'PEHepatic', 'PEHepaticDesc', \n",
    "                        'PEGU', 'PEGUDesc', 'PERenal', 'PERenalDesc', 'PENeuro', 'PENeuroDesc', \n",
    "                        'PEPsych', 'PEPsychDesc', 'PEEndo', 'PEEndoDesc', 'PEHema', 'PEHemaDesc', \n",
    "                        'PEMusculo', 'PEMusculoDesc', 'PEDerm', 'PEDermDesc', 'PEAllergies', \n",
    "                        'PEAllergiesDesc', 'PEImmune', 'PEImmuneDesc', 'PEAlcohol', 'PEAlcoholDesc', \n",
    "                        'PEDAY']].copy()  # <-- Use .copy() to avoid issues\n",
    "\n",
    "df_pe.loc[:, 'HEENT_Class'] = df_pe['PEHEENT'].apply(lambda x: 1 if x == 'Abnormal' else 0)\n",
    "df_pe['PEHEENT'] = df_pe['PEHEENT'].str.strip()\n",
    "df_pe.loc[:, 'Cardio_Class'] = df_pe['PECardio'].apply(lambda x: 1 if x == 'Abnormal' else 0)\n",
    "df_pe['PECardio'] = df_pe['PECardio'].str.strip()\n",
    "df_pe.loc[:, 'Resp_Class'] = df_pe['PEResp'].apply(lambda x: 1 if x == 'Abnormal' else 0)\n",
    "df_pe['PEResp'] = df_pe['PEResp'].str.strip()\n",
    "df_pe.loc[:, 'GI_Class'] = df_pe['PEGI'].apply(lambda x: 1 if x == 'Abnormal' else 0)\n",
    "df_pe['PEGI'] = df_pe['PEGI'].str.strip()\n",
    "df_pe.loc[:, 'Hepatic_Class'] = df_pe['PEHepatic'].apply(lambda x: 1 if x == 'Abnormal' else 0)\n",
    "df_pe['PEHepatic'] = df_pe['PEHepatic'].str.strip()\n",
    "df_pe.loc[:, 'GU_Class'] = df_pe['PEGU'].apply(lambda x: 1 if x == 'Abnormal' else 0)\n",
    "df_pe['PEGU'] = df_pe['PEGU'].str.strip()\n",
    "df_pe.loc[:, 'Renal_Class'] = df_pe['PERenal'].apply(lambda x: 1 if x == 'Abnormal' else 0)\n",
    "df_pe['PERenal'] = df_pe['PERenal'].str.strip()\n",
    "df_pe.loc[:, 'Neuro_Class'] = df_pe['PENeuro'].apply(lambda x: 1 if x == 'Abnormal' else 0)\n",
    "df_pe['PENeuro'] = df_pe['PENeuro'].str.strip()\n",
    "df_pe.loc[:, 'Psych_Class'] = df_pe['PEPsych'].apply(lambda x: 1 if x == 'Abnormal' else 0)\n",
    "df_pe['PEPsych'] = df_pe['PEPsych'].str.strip()\n",
    "df_pe.loc[:, 'Endo_Class'] = df_pe['PEEndo'].apply(lambda x: 1 if x == 'Abnormal' else 0)\n",
    "df_pe['PEEndo'] = df_pe['PEEndo'].str.strip()\n",
    "df_pe.loc[:, 'Heme_Class'] = df_pe['PEHema'].apply(lambda x: 1 if x == 'Abnormal' else 0)\n",
    "df_pe['PEHema'] = df_pe['PEHema'].str.strip()\n",
    "df_pe.loc[:, 'MSK_Class'] = df_pe['PEMusculo'].apply(lambda x: 1 if x == 'Abnormal' else 0)\n",
    "df_pe['PEMusculo'] = df_pe['PEMusculo'].str.strip()\n",
    "df_pe.loc[:, 'Derm_Class'] = df_pe['PEDerm'].apply(lambda x: 1 if x == 'Abnormal' else 0)\n",
    "df_pe['PEDerm'] = df_pe['PEDerm'].str.strip()\n",
    "df_pe.loc[:, 'Allergy_Class'] = df_pe['PEAllergies'].apply(lambda x: 1 if x == 'Abnormal' else 0)\n",
    "df_pe['PEAllergies'] = df_pe['PEAllergies'].str.strip()\n",
    "df_pe.loc[:, 'Immune_Class'] = df_pe['PEImmune'].apply(lambda x: 1 if x == 'Abnormal' else 0)\n",
    "df_pe['PEImmune'] = df_pe['PEImmune'].str.strip()\n",
    "df_pe.loc[:, 'Alcohol_Class'] = df_pe['PEAlcohol'].apply(lambda x: 1 if x == 'Abnormal' else 0)\n",
    "df_pe['PEAlcohol'] = df_pe['PEAlcohol'].str.strip()\n",
    "\n",
    "#display head \n",
    "df_pe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13061ce3-8b05-487a-a9c4-4f967e41eb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Above converted to a function\n",
    "def one_hot_encode(df, finding_columns):\n",
    "    \"\"\"\n",
    "    One-hot encodes columns from df. If 'Abnormal', then 1.\n",
    "    Strips whitespace from original column\n",
    "    Returns df\n",
    "    \"\"\"\n",
    "\n",
    "    for col in finding_columns:\n",
    "        class_col = f'{col[2:]}_Class'  # Create class column name (e.g., HEENT_Class)\n",
    "        df.loc[:, class_col] = df[col].apply(lambda x: 1 if x == 'Abnormal' else 0)\n",
    "        df[col] = df[col].str.strip()\n",
    "\n",
    "    return df\n",
    "\n",
    "df_pe = df_pe_original[['PUDID', 'PETime', 'PEHEENT', 'PEHEENTDesc', 'PECardio', 'PECardioDesc', \n",
    "                        'PEResp', 'PERespDesc', 'PEGI', 'PEGIDesc', 'PEHepatic', 'PEHepaticDesc', \n",
    "                        'PEGU', 'PEGUDesc', 'PERenal', 'PERenalDesc', 'PENeuro', 'PENeuroDesc', \n",
    "                        'PEPsych', 'PEPsychDesc', 'PEEndo', 'PEEndoDesc', 'PEHema', 'PEHemaDesc', \n",
    "                        'PEMusculo', 'PEMusculoDesc', 'PEDerm', 'PEDermDesc', 'PEAllergies', \n",
    "                        'PEAllergiesDesc', 'PEImmune', 'PEImmuneDesc', 'PEAlcohol', 'PEAlcoholDesc', \n",
    "                        'PEDAY']].copy()\n",
    "finding_columns = [\n",
    "    'PEHEENT', 'PECardio', 'PEResp', 'PEGI', 'PEHepatic', 'PEGU', 'PERenal', 'PENeuro', 'PEPsych', 'PEEndo', 'PEHema', 'PEMusculo', \n",
    "    'PEDerm','PEAllergies', 'PEImmune', 'PEAlcohol']\n",
    "\n",
    "one_hot_encode(df_pe, finding_columns)\n",
    "df_pe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4fa0ed-0c94-4dbc-8d93-23812bce5043",
   "metadata": {},
   "source": [
    "## Regex Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f6f500-9e8c-4624-9222-e4a7f41991f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data cleaning\n",
    "\n",
    "#should we have different df for each system? I do not think so but will need to do a lot of replacing \n",
    "#HEENT - going to have to combine everything that says a version of dry mouth, dry mucous etc. into a single term - even some things that say 'Tacky M'\n",
    "#Cardio - tachycardic and all versions of that spelling\n",
    "#Resp - Kussmaul and all versions of that spelling, tachypnic \n",
    "#GI - all terms associated with abdominal tenderness, nausea/emesis\n",
    "#GU - polyuria and anything mentioning increased urine output\n",
    "#Renal - polyuria as above, will have to be careful not to double count \n",
    "#Neuro - this part is going to be really hard, possibly should just use GCS for this part \n",
    "#Psych - Tired, altered, etc. \n",
    "#Endo - hyperglycemia/history of DKA?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdcd04e-066d-4d8d-ae4b-8583f2a0d765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_binary_flag(df, description_column, new_column, search_patterns, regex=False):\n",
    "    \"\"\"\n",
    "    Creates a binary flag based on the presence of specified search patterns in the description column.\n",
    "    regex = False -> treated as literal strings. When regex = True, you can use regex in the search_patterns\n",
    "    \"\"\"\n",
    "\n",
    "    if description_column not in df.columns:\n",
    "        raise ValueError(f\"'{description_column}' not found in {df} columns.\")\n",
    "    if not search_patterns:\n",
    "        return df\n",
    "\n",
    "    df[new_column] = 0\n",
    "    #df.loc[df[description_column].isna(), new_column] = np.nan # We don't need to put nulls in\n",
    "\n",
    "    for pattern in search_patterns:\n",
    "        df.loc[df[description_column].str.lower() == pattern.lower(), new_column] = 1\n",
    "\n",
    "    for pattern in search_patterns:\n",
    "        if regex:\n",
    "            df.loc[df[description_column].str.contains(pattern, case=False, na=False, regex=True) & (df[new_column] == 0), new_column] = 1\n",
    "        else:\n",
    "            df.loc[df[description_column].str.contains(pattern, case=False, na=False, regex=False) & (df[new_column] == 0), new_column] = 1\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25494f13-ba95-4e3a-905a-e467d203fc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HEENT Dry_MM\n",
    "#df_pe = create_binary_flag(df_pe, 'PEHEENTDesc', 'HEENT_DryMM', [\"dry muc\", \"drymm\", \"dry lip\"], regex=True) # original line\n",
    "ENT_search = r'(?:dry|muc(?:ous|us|ous membrane|us membrane|mm)|mm|tacky)'\n",
    "df_pe = create_binary_flag(df_pe, 'PEHEENTDesc', 'HEENT_DryMM', [ENT_search], regex=True)\n",
    "\n",
    "#print(df_pe.loc[df_pe['PEHEENT'] == 'Abnormal', ['PEHEENT', 'PEHEENTDesc', 'HEENT_DryMM']].head(50)) # Test print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b37c678-48f1-454a-b45c-ba4c7d62a5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cardio Tachy:\n",
    "#df_pe = create_binary_flag(df_pe, 'PECardioDesc', 'Cardio_Tachy', [\"tachycardic\", \"tachycardia\"]) # Original\n",
    "df_pe = create_binary_flag(df_pe, 'PECardioDesc', 'Cardio_Tachy', [r'(?:tachy(?!p)\\w*|elevated)'], regex=True)\n",
    "\n",
    "#print(df_pe.loc[df_pe['PECardio'] == 'Abnormal', ['PECardio', 'PECardioDesc', 'Cardio_Tachy']].head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25573ad0-2680-4299-9e6e-ade05d2b6f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = 'PERespDesc'\n",
    "\n",
    "all_terms = df_pe[column_name].str.split(expand=True).stack().str.lower()\n",
    "\n",
    "term_counts = all_terms.value_counts()\n",
    "\n",
    "print(f\"Top 10 Terms in '{column_name}':\")\n",
    "for term, count in term_counts.head(10).items():\n",
    "    print(f\"{term}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cf0209-0db4-461e-912a-8bbe05cad59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resp Tachy - we will need to include all cases or do regex to figure out how to do it with capitals etc.\n",
    "#df_pe = create_binary_flag(df_pe, 'PERespDesc', 'Resp_Tachy', ['tachypnea','Tachypnea','tachycardia', 'Tachypneic'])\n",
    "df_pe = create_binary_flag(df_pe, 'PERespDesc', 'Resp_Tachy', [r'tachy\\w*|kuss\\w*'], regex=True)\n",
    "\n",
    "#print(df_pe.loc[df_pe['PEResp'] == 'Abnormal', ['PEResp', 'PERespDesc', 'Resp_Tachy']].head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a681d9-3eb9-4656-954f-11fc142d87c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resp Kuss: This is going to have to contain every version of the spelling because it is spelled wrong a lot \n",
    "df_pe = create_binary_flag(df_pe, 'PERespDesc', 'Resp_Kuss', [r'kuss\\w*'], regex=True)\n",
    "\n",
    "#print(df_pe.loc[df_pe['PEResp'] == 'Abnormal', ['PEResp', 'PERespDesc', 'Resp_Kuss']].head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb22919e-c61e-48aa-a1c1-0d495c222d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GI - Tender\n",
    "\n",
    "#GI - Nausea/Vomiting\n",
    "\n",
    "#GU - Polyuria + Frequency + Urinating alot + Increased Urination\n",
    "\n",
    "#Renal - we might have to combine renal and GU because they both say polyuria (not sure if you can do that with create_binary\n",
    "\n",
    "#Neuro - Sleepy/Lethargic/Altered Mental Status/Somnolent/Listless/Fatigued/Tired/Drowsy\n",
    "\n",
    "#Psych - Agitated/Distressed/Irritable/\n",
    "\n",
    "#Endo - I am not sure what to do with this one but I am inclined to leave it out or only use ketotic breath/acetone breath\n",
    "\n",
    "#MSK - Thin - 'Cachectic'- 'Thin-appearing' 'Thin extremities' etc. \n",
    "\n",
    "#MSK - Muscle Pain - 'Myalgia' 'Muscle Pain' \n",
    "\n",
    "# DERM - Pallor/Pale skin\n",
    "\n",
    "# DERM - Dry skin\n",
    "\n",
    "\n",
    "df_pe.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5c2a1d-9225-4e4e-b95d-2bab0315382e",
   "metadata": {},
   "source": [
    "## Date Time\n",
    "****Converting Physical Exam Time to Date Time****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64cbf71-2cf7-494f-b392-e9b6ae55dd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#covnerting PETime to datetime\n",
    "\n",
    "#first convert to string for date time function\n",
    "df_pe['PETime'] = (df_pe['PETime']).astype(str)\n",
    "\n",
    "#some values are single digits - assuming there are leading zeros\n",
    "df_pe.loc[df_pe[\"PETime\"] == \"0\", \"PETime\"] = \"0000\"\n",
    "df_pe.loc[df_pe[\"PETime\"] == \"1\", \"PETime\"] = \"0001\"\n",
    "df_pe.loc[df_pe[\"PETime\"] == \"2\", \"PETime\"] = \"0002\"\n",
    "df_pe.loc[df_pe[\"PETime\"] == \"4\", \"PETime\"] = \"0004\"\n",
    "df_pe.loc[df_pe[\"PETime\"] == \"9\", \"PETime\"] = \"0009\"\n",
    "\n",
    "#convert to time\n",
    "df_pe['PETime'] = pd.to_datetime(df_pe['PETime'], format='%H%M').dt.time# Print the DataFrameprint(df)\n",
    "df_pe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bcd52c-79b8-4415-a2c4-b03218b6fdb7",
   "metadata": {},
   "source": [
    "**Imaging data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48366de-5ce3-4dec-8e1c-ad6b3f3e9b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in imaging data\n",
    "imaging = pd.read_csv(\"IMAGING.csv\")\n",
    "imaging.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56eccf7-1afd-4be6-9cfd-8dd282b750fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change time to datetime\n",
    "imaging['ImageTime'] = imaging['ImageTime'].astype(str).str.zfill(4) #add leading zeros where time is less than 4 digits\n",
    "#convert to time\n",
    "imaging['ImageTime'] = pd.to_datetime(imaging['ImageTime'], format='%H%M').dt.time # Print the DataFrameprint(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596d683d-4c9a-44cc-9db3-8b7bd7b6b458",
   "metadata": {},
   "source": [
    "**Merge physical exam and imaging dataframes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7382d688-a7ee-4247-b943-b614471b3fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge dataframes\n",
    "df_pe_imaging = pd.merge(df_pe, imaging, how ='outer', on ='PUDID') \n",
    "\n",
    "#drop extra columns\n",
    "df_pe_imaging.drop(['StudyEvent','Occurrence', 'ItemGroupRepeatKey'], axis = 1)\n",
    "df_pe_imaging.head()\n",
    "#df_pe_imaging.shape #there are some patients with multiple imaging times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab89764-798e-46da-8c51-0783d936b214",
   "metadata": {},
   "source": [
    "***Converting imaging times to actual date times based on IMAGEDAY and PEDAY***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5a8e72-6ae1-4420-bcad-60c9045499a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating reference date - change if there is a real reference date for each patient visit\n",
    "\n",
    "df_pe_imaging[\"ImageTime\"] = df_pe_imaging[\"ImageTime\"].astype(str)\n",
    "df_pe_imaging[\"PETime\"] = df_pe_imaging[\"PETime\"].astype(str)\n",
    "\n",
    "# Convert ImageTime to timedelta\n",
    "df_pe_imaging[\"ImageTime\"] = pd.to_timedelta(df_pe_imaging[\"ImageTime\"])\n",
    "df_pe_imaging[\"PETime\"] = pd.to_timedelta(df_pe_imaging[\"PETime\"])\n",
    "\n",
    "# Set reference date\n",
    "reference_date = pd.to_datetime(\"2025-01-01\")\n",
    "\n",
    "# Compute full datetime\n",
    "df_pe_imaging[\"ImagingDateTime\"] = reference_date + pd.to_timedelta(df_pe_imaging[\"IMAGEDAY\"], unit=\"D\") + df_pe_imaging[\"ImageTime\"]\n",
    "df_pe_imaging[\"ExamDateTime\"] = reference_date + pd.to_timedelta(df_pe_imaging[\"PEDAY\"], unit=\"D\") + df_pe_imaging[\"PETime\"]\n",
    "\n",
    "df_pe_imaging.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677a4b60-b923-4f28-991c-bddd4ac5626d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d539517-4588-4b85-bcd4-a03266bade98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c4d0b3c-1e96-48f3-873b-d1559e173c26",
   "metadata": {},
   "source": [
    "*Demographics*\n",
    "* Sex = Sex\n",
    "* Ethnicity = Ethnicity \n",
    "* Race 1 = American Indian or Alaska Native \n",
    "* Race 2 = Asian\n",
    "* Race 3 = Black or African American\n",
    "* Race 3 = Native Hawaiian or Other Pacific Islander \n",
    "* Race 5 = White\n",
    "* Race 92 = Unknown or Not Reported\n",
    "* AgeInYears = Age in years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a9f886-e38b-4680-a63a-0e89fe91f787",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo = pd.read_csv('Demographics.csv')\n",
    "\n",
    "df_demo = df_demo[['PUDID', 'Sex', 'Ethnicity', 'Race1', 'Race2', 'Race3', 'Race4', 'Race5', 'Race92', 'AgeInYears']]\n",
    "\n",
    "#Rename the columns \n",
    "df_demo = df_demo.rename(columns={\n",
    "    'Race1': 'American Indian or Alaska Native',\n",
    "    'Race2': 'Asian',\n",
    "    'Race3': 'Black or African American',\n",
    "    'Race4': 'Native Hawaiian or Other Pacific Islander',\n",
    "    'Race5': 'White',\n",
    "    'Race92': 'Unknown or Not Reported',\n",
    "    'AgeInYears': 'Age'\n",
    "})\n",
    "\n",
    "#Total number of patients\n",
    "total = len(df_demo['PUDID'])\n",
    "print(\"Total number of patients:\", total)\n",
    "\n",
    "# Create a dictionary to store value counts for each category\n",
    "summary_data = {\n",
    "    'Sex': df_demo['Sex'].value_counts(),\n",
    "    'Ethnicity': df_demo['Ethnicity'].value_counts(),\n",
    "    'American Indian or Alaska Native': df_demo['American Indian or Alaska Native'].value_counts(), \n",
    "    'Asian': df_demo['Asian'].value_counts(),\n",
    "    'Black or African American': df_demo['Black or African American'].value_counts(),\n",
    "    'Native Hawaiian or Other Pacific Islander': df_demo['Native Hawaiian or Other Pacific Islander'].value_counts(),\n",
    "    'White': df_demo['White'].value_counts(),\n",
    "    'Unknown or Not Reported': df_demo['Unknown or Not Reported'].value_counts(),\n",
    "}\n",
    "\n",
    "#Convert dictionary to DataFrame\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "# Display the summary table\n",
    "print(summary_df)\n",
    "\n",
    "df_demo['Age'].describe(percentiles = [.25, .5, .75])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bf1cfe-fa34-4bab-ae6b-34f006399175",
   "metadata": {},
   "source": [
    "*Creating simple figures for demographics*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ec4675-a6fa-4a98-a8b6-153b1d6a3306",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing Race to 1/0s for easier plotting\n",
    "df_demo[['American Indian or Alaska Native', 'Asian', 'Black or African American', 'Native Hawaiian or Other Pacific Islander',\n",
    "'White','Unknown or Not Reported']] = (df_demo[['American Indian or Alaska Native', 'Asian', 'Black or African American', 'Native Hawaiian or Other Pacific Islander',\n",
    "'White','Unknown or Not Reported']]).replace({\"Yes\":1, \"No\":0})\n",
    "df_demo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5e9595-58a4-419b-9d68-b50e56b7eb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplot lib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a5c02b-a0ae-4d6a-9fd8-7389efa67635",
   "metadata": {},
   "outputs": [],
   "source": [
    "#histogram for age\n",
    "fig = plt.figure(figsize = (10,6))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(df_demo['Age'],\n",
    "        bins = 19,\n",
    "        range = (0,18),\n",
    "                color = 'steelblue',\n",
    "       edgecolor = 'white') \n",
    "ax.set_title(\"Age of DKA Patients\")\n",
    "ax.set_ylabel(\"Patient Count\")\n",
    "ax.text(0.2, 0.9, \"Mean age (SD) = 11.6 (4.1)\", fontsize=10, ha=\"center\", transform=ax.transAxes)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81838886-569f-40ca-a7d2-37e2483b4feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create race counts\n",
    "\n",
    "#subset dataframe for just race columns\n",
    "race_counts = df_demo[['American Indian or Alaska Native', 'Asian', 'Black or African American', 'Native Hawaiian or Other Pacific Islander',\n",
    "'White','Unknown or Not Reported']].sum()\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,6))\n",
    "ax.bar(race_counts.index, race_counts.values,\n",
    "                color = 'cornflowerblue')\n",
    "       \n",
    "ax.set_title(\"Patient Race\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "plt.xticks(rotation = 45, ha = 'right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d6ce90-e99e-467b-a26c-ee7652994ec8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#HEENT\n",
    "\n",
    "# #Create Dry_MM column\n",
    "# df['HEENT_DryMM'] = 0\n",
    "\n",
    "# # #Apply sequential filters\n",
    "# df.loc[df['PEHEENTDesc'].str.contains('dry muc', case=False, na=False), 'HEENT_DryMM'] = 1\n",
    "# df.loc[df['PEHEENTDesc'].str.contains('drymm', case=False, na=False), 'HEENT_DryMM'] = 1\n",
    "# df.loc[df['PEHEENTDesc'].str.contains('dry lip', case=False, na=False), 'HEENT_DryMM'] = 1\n",
    "\n",
    "\n",
    "# #print(df[df['PEHEENTDesc'].str.contains(\"dry mucous\", case = False, na = False)])\n",
    "# # df.dtypes\n",
    "# df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0f1004-4b53-4586-96d6-800ce2b5b11b",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "#Cardio\n",
    "\n",
    "#Create tachycardio column\n",
    "df['Cardio_Tachy'] = 0\n",
    "\n",
    "#Apply sequential filters\n",
    "df.loc[df['PECardioDesc'] == 'tachycardic', 'Cardio_Tachy'] = 1\n",
    "df.loc[df['PECardioDesc'] == 'tachycardia', 'Cardio_Tachy'] = 1\n",
    "df.loc[df['PECardioDesc'].str.contains('tachycardic', case=False, na=False), 'Cardio_Tachy'] = 1\n",
    "df.loc[df['PECardioDesc'].str.contains('tachycardia', case=False, na=False), 'Cardio_Tachy'] = 1\n",
    "\n",
    "# df.dtypes\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc5aeee-4123-4995-9c45-b80ad671f3a6",
   "metadata": {},
   "source": [
    "##Resp \n",
    "\n",
    "#Create tachypnea column\n",
    "df['Resp_Tachy'] = 0\n",
    "\n",
    "#Create Kussmaul\n",
    "df['Resp_Kuss'] = 0\n",
    "\n",
    "#Apply sequential filters to resp_tachy\n",
    "df.loc[df['PERespDesc'] == 'tachypnea', 'Resp_Tachy'] = 1\n",
    "df.loc[df['PERespDesc'] == 'tachycardia', 'Resp_Tachy'] = 1\n",
    "\n",
    "#Apply sequential filters to resp_kuss\n",
    "#df.loc[df['PERespDesc'] == 'Kussmaul', 'Resp_Kuss'] = 1\n",
    "df.loc[df['PERespDesc'].str.contains('Kuss', case=False, na=False), 'Resp_Kuss'] = 1\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebddb5a7-ab01-4c86-88b7-db7be99f85f9",
   "metadata": {},
   "source": [
    "##GI \n",
    "\n",
    "#Create abdominal pain column\n",
    "df['GI_Pain'] = 0\n",
    "\n",
    "#Create Kussmaul\n",
    "df[''] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a06e34d-df78-4938-8f71-5646b845d33e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b5a689-4969-4196-b0ad-81aa5972c9aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc63b2a-d7bf-4f4d-90ba-6794162e69af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5144050-8872-4c60-a27b-e464019d2ee8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
